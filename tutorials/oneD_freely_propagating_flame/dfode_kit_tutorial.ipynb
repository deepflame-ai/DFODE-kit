{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44caac4b",
   "metadata": {},
   "source": [
    "This is a tutorial for the DFODE-kit package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84b1a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dfode_kit.df_interface import (\n",
    "    OneDFreelyPropagatingFlameConfig,\n",
    "    setup_one_d_flame_case,\n",
    "    df_to_h5,\n",
    ")\n",
    "from dfode_kit.data_operations import (\n",
    "    touch_h5, \n",
    "    get_TPY_from_h5, \n",
    "    random_perturb,\n",
    "    label_npy,\n",
    "    integrate_h5,\n",
    ")\n",
    "from dfode_kit.dfode_core.model.mlp import MLP\n",
    "from dfode_kit.utils import BCT\n",
    "\n",
    "DFODE_ROOT = os.environ['DFODE_ROOT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032661c",
   "metadata": {},
   "source": [
    "### A brief introduction to the DFODE method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a592b7b",
   "metadata": {},
   "source": [
    "#### Low-dimensional manifold sampling\n",
    "\n",
    "A key challenge in preparing training data is achieving sufficient coverage of the relevant thermochemical composition space, which is often prohibitively high-dimensional when detailed chemistry involves tens to hundreds of species. \n",
    "\n",
    "To address this, DFODE-kit adopts a low-dimensional\n",
    "manifold sampling strategy, where thermochemical states are extracted from canonical flame configurations that retain the essential topology of high-dimensional turbulent flames. This approach ensures both computational efficiency and physical representativeness of the training datasets.\n",
    "\n",
    "In this tutorial, we will demonstrate how to use DFODE-kit to sample a low-dimensional manifold of thermochemical states from a one-dimensional laminar freely propagating flame simulated with DeepFlame. The following code block could also be found in `case_init.ipynb` files within the case templates provides in the `cases` directory. It is used to initialize the simulation and update the dictionary files for the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f58d8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving premixed flame...\n",
      "Laminar Flame Speed      :   2.3489328863 m/s\n",
      "Laminar Flame Thickness  :   0.0003694362 m\n",
      "One-dimensional flame case setup completed at: /data1/kexiao/projects/dfode_project/DFODE-kit/tutorials/oneD_freely_propagating_flame\n"
     ]
    }
   ],
   "source": [
    "# Operating condition settings\n",
    "config_dict = {\n",
    "    \"mechanism\": f\"{DFODE_ROOT}/mechanisms/Burke2012_s9r23.yaml\",\n",
    "    \"T0\": 300,\n",
    "    \"p0\": 101325,\n",
    "    \"fuel\": \"H2:1\",\n",
    "    \"oxidizer\": \"O2:0.21,N2:0.79\",\n",
    "    \"eq_ratio\": 1.0,\n",
    "}\n",
    "config = OneDFreelyPropagatingFlameConfig(**config_dict)\n",
    "\n",
    "# Simulation settings\n",
    "settings = {\n",
    "    \"sim_time_step\": 1e-6,\n",
    "    \"sim_write_interval\": 1e-5,\n",
    "    \"num_output_steps\": 10,\n",
    "}\n",
    "config.update_config(settings)\n",
    "\n",
    "# Setup the case and update dictionary files\n",
    "setup_one_d_flame_case(config, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbbe369",
   "metadata": {},
   "source": [
    "Note that at the point, the simulation is not yet started. The user would need to ensure a working version of DeepFlame is available and run the `Allrun` script from command line to start the simulation.\n",
    "\n",
    "```bash\n",
    "./Allrun\n",
    "```\n",
    "\n",
    "After the simulation is completed, we proceed to use DFODE-kit to gather and manage the thermochemical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd60205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species names: ['T', 'p', 'H', 'H2', 'O', 'OH', 'H2O', 'O2', 'HO2', 'H2O2', 'N2']\n",
      "Saved concatenated arrays to /data1/kexiao/projects/dfode_project/DFODE-kit/tutorials/oneD_freely_propagating_flame/tutorial_data.h5\n"
     ]
    }
   ],
   "source": [
    "df_to_h5(\n",
    "    root_dir=f\"{DFODE_ROOT}/tutorials/oneD_freely_propagating_flame\",\n",
    "    mechanism=f\"{DFODE_ROOT}/mechanisms/Burke2012_s9r23.yaml\",\n",
    "    hdf5_file_path=f\"{DFODE_ROOT}/tutorials/oneD_freely_propagating_flame/tutorial_data.h5\",\n",
    "    include_mesh=True,\n",
    ")\n",
    "\n",
    "# The above is equivalent to the following cli command:\n",
    "# dfode-kit sample --mech Burke2012_s9r23.yaml \\\n",
    "#     --case tutorials/oneD_freely_propagating_flame \\\n",
    "#     --save tutorials/oneD_freely_propagating_flame/tutorial_data.h5 \\\n",
    "#     --include-mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b991ab21",
   "metadata": {},
   "source": [
    "Checking the contents of the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5b45c7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting HDF5 file: tutorial_data.h5\n",
      "\n",
      "Metadata in the HDF5 file:\n",
      "mechanism: /data1/kexiao/projects/dfode_project/DFODE-kit/mechanisms/Burke2012_s9r23.yaml\n",
      "root_directory: /data1/kexiao/projects/dfode_project/DFODE-kit/tutorials/oneD_freely_propagating_flame\n",
      "species_names: ['T' 'p' 'H' 'H2' 'O' 'OH' 'H2O' 'O2' 'HO2' 'H2O2' 'N2']\n",
      "\n",
      "Groups and datasets in the HDF5 file:\n",
      "Group: mesh\n",
      "  Dataset: Cx, Shape: (500, 1)\n",
      "  Dataset: Cy, Shape: (500, 1)\n",
      "  Dataset: Cz, Shape: (500, 1)\n",
      "  Dataset: V, Shape: (500, 1)\n",
      "Group: scalar_fields\n",
      "  Dataset: 0.0001, Shape: (500, 11)\n",
      "  Dataset: 0.00011, Shape: (500, 11)\n",
      "  Dataset: 1e-05, Shape: (500, 11)\n",
      "  Dataset: 2e-05, Shape: (500, 11)\n",
      "  Dataset: 3e-05, Shape: (500, 11)\n",
      "  Dataset: 4e-05, Shape: (500, 11)\n",
      "  Dataset: 5e-05, Shape: (500, 11)\n",
      "  Dataset: 6e-05, Shape: (500, 11)\n",
      "  Dataset: 7e-05, Shape: (500, 11)\n",
      "  Dataset: 8e-05, Shape: (500, 11)\n",
      "  Dataset: 9e-05, Shape: (500, 11)\n"
     ]
    }
   ],
   "source": [
    "touch_h5(\"tutorial_data.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779899a3",
   "metadata": {},
   "source": [
    "#### Data augmentation and labeling\n",
    "\n",
    "While laminar canonical flames provide fundamental thermochemical states,their trajectory-aligned sampling in composition space poses significant limitations for a posteriori modeling applications. First, these sampled states are confined to predefined flamelet manifolds, making the trained model highly sensitive to perturbations and leading to an over-constrained representation. Second, the sampled states span a lower-dimensional subspace, which fails to encompass the full range of thermochemical variations encountered in turbulent combustion. As a result, the model becomes vulnerable to off-manifold perturbationsâ€”deviations from the training manifold that frequently arise in turbulent reacting flows.\n",
    "\n",
    "To tackle this challenge, a data augmentation strategy is employed, where collected states are perturbed to simulate the effects of multi-dimensional transport and turbulence disturbances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ece01cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets in scalar_fields group: 11\n",
      "[3.00023e+02 1.02883e+05 1.50501e-41 2.85116e-02 1.63881e-47 9.68647e-48\n",
      " 8.28493e-48 2.26269e-01 5.70836e-38 2.00401e-52 7.45219e-01]\n",
      "[4.34898431e+02 1.03023870e+05 1.30235941e-44 3.73487006e-02\n",
      " 3.76889810e-47 3.09947306e-51 2.86370158e-49 2.17432299e-01\n",
      " 1.17072095e-35 5.19600513e-56 7.45219000e-01]\n"
     ]
    }
   ],
   "source": [
    "thermochemical_data = get_TPY_from_h5(\"tutorial_data.h5\")\n",
    "print(thermochemical_data[0])\n",
    "\n",
    "aug_thermochemical_data = random_perturb(thermochemical_data)\n",
    "print(aug_thermochemical_data[0])\n",
    "\n",
    "np.save(\"tutorial_data_aug.npy\", aug_thermochemical_data)\n",
    "\n",
    "# The above is equivalent to the following cli command:\n",
    "# dfode-kit augment --h5_file tutorial_data.h5 \\\n",
    "#     --output_file tutorial_data_aug.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f2d8f",
   "metadata": {},
   "source": [
    "The CVODE integrator from Cantera is used for time integration and to provide supervised learning labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ff47da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from: tutorial_data_aug.npy\n",
      "test_data.shape=(5500, 11)\n",
      "Total time used: 0.93 seconds\n",
      "labeled_data.shape=(5500, 22)\n",
      "[4.34898431e+02 1.03023870e+05 1.30235941e-44 3.73487006e-02\n",
      " 3.76889810e-47 3.09947306e-51 2.86370158e-49 2.17432299e-01\n",
      " 1.17072095e-35 5.19600513e-56 7.45219000e-01 4.34898431e+02\n",
      " 1.03023870e+05 6.04320390e-29 3.73487006e-02 1.27860203e-32\n",
      " 6.60575312e-33 7.74753499e-33 2.17432299e-01 9.72749461e-27\n",
      " 1.52164666e-36 7.45219000e-01]\n"
     ]
    }
   ],
   "source": [
    "labeled_data = label_npy(\n",
    "    mech_path=f\"{DFODE_ROOT}/mechanisms/Burke2012_s9r23.yaml\",\n",
    "    time_step=1e-6,\n",
    "    source_path=\"tutorial_data_aug.npy\",\n",
    ")\n",
    "\n",
    "print(f'{labeled_data.shape=}')\n",
    "print(labeled_data[0])\n",
    "np.save(\"tutorial_data_labeled.npy\", labeled_data)\n",
    "\n",
    "# The above is equivalent to the following cli command:\n",
    "# dfode-kit label --mech Burke2012_s9r23.yaml \\\n",
    "#     --time 1e-6 \\\n",
    "#     --source tutorial_data_aug.npy \\\n",
    "#     --save tutorial_data_labeled.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc291e95",
   "metadata": {},
   "source": [
    "#### Model training\n",
    "\n",
    "Only a demo for training a model is provided here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d5aa0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.5456070303916931\n",
      "Epoch: 1, Loss: 0.5291376113891602\n",
      "Epoch: 2, Loss: 0.5356059074401855\n",
      "Epoch: 3, Loss: 0.5246405601501465\n",
      "Epoch: 4, Loss: 0.5228965878486633\n",
      "Epoch: 5, Loss: 0.5245605111122131\n",
      "Epoch: 6, Loss: 0.5222760438919067\n",
      "Epoch: 7, Loss: 0.5164884924888611\n",
      "Epoch: 8, Loss: 0.5139819383621216\n",
      "Epoch: 9, Loss: 0.5166049003601074\n",
      "Epoch: 10, Loss: 0.5146443247795105\n",
      "Epoch: 11, Loss: 0.5114165544509888\n",
      "Epoch: 12, Loss: 0.5117149949073792\n",
      "Epoch: 13, Loss: 0.5111161470413208\n",
      "Epoch: 14, Loss: 0.5108492970466614\n",
      "Epoch: 15, Loss: 0.5098523497581482\n",
      "Epoch: 16, Loss: 0.5081254243850708\n",
      "Epoch: 17, Loss: 0.5057773590087891\n",
      "Epoch: 18, Loss: 0.5046067833900452\n",
      "Epoch: 19, Loss: 0.5039052367210388\n",
      "Epoch: 20, Loss: 0.5029950737953186\n",
      "Epoch: 21, Loss: 0.501594603061676\n",
      "Epoch: 22, Loss: 0.5002539753913879\n",
      "Epoch: 23, Loss: 0.4999106824398041\n",
      "Epoch: 24, Loss: 0.49878478050231934\n",
      "Epoch: 25, Loss: 0.49734410643577576\n",
      "Epoch: 26, Loss: 0.4964168071746826\n",
      "Epoch: 27, Loss: 0.49534714221954346\n",
      "Epoch: 28, Loss: 0.49454864859580994\n",
      "Epoch: 29, Loss: 0.49396219849586487\n",
      "Epoch: 30, Loss: 0.49287813901901245\n",
      "Epoch: 31, Loss: 0.491438627243042\n",
      "Epoch: 32, Loss: 0.48938319087028503\n",
      "Epoch: 33, Loss: 0.4872249662876129\n",
      "Epoch: 34, Loss: 0.48472893238067627\n",
      "Epoch: 35, Loss: 0.4815191626548767\n",
      "Epoch: 36, Loss: 0.4776597023010254\n",
      "Epoch: 37, Loss: 0.47582685947418213\n",
      "Epoch: 38, Loss: 0.4860130250453949\n",
      "Epoch: 39, Loss: 0.47126731276512146\n",
      "Epoch: 40, Loss: 0.4685119390487671\n",
      "Epoch: 41, Loss: 0.4679502248764038\n",
      "Epoch: 42, Loss: 0.45636725425720215\n",
      "Epoch: 43, Loss: 0.46242964267730713\n",
      "Epoch: 44, Loss: 0.44730475544929504\n",
      "Epoch: 45, Loss: 0.4477929472923279\n",
      "Epoch: 46, Loss: 0.44682860374450684\n",
      "Epoch: 47, Loss: 0.43026649951934814\n",
      "Epoch: 48, Loss: 0.43145889043807983\n",
      "Epoch: 49, Loss: 0.4414179027080536\n",
      "Epoch: 50, Loss: 0.43130263686180115\n",
      "Epoch: 51, Loss: 0.41154447197914124\n",
      "Epoch: 52, Loss: 0.41563481092453003\n",
      "Epoch: 53, Loss: 0.4169149696826935\n",
      "Epoch: 54, Loss: 0.4085693359375\n",
      "Epoch: 55, Loss: 0.4125063419342041\n",
      "Epoch: 56, Loss: 0.394435316324234\n",
      "Epoch: 57, Loss: 0.40447694063186646\n",
      "Epoch: 58, Loss: 0.3860774040222168\n",
      "Epoch: 59, Loss: 0.38175034523010254\n",
      "Epoch: 60, Loss: 0.3952062129974365\n",
      "Epoch: 61, Loss: 0.3695756196975708\n",
      "Epoch: 62, Loss: 0.3751007914543152\n",
      "Epoch: 63, Loss: 0.3642053008079529\n",
      "Epoch: 64, Loss: 0.3585515320301056\n",
      "Epoch: 65, Loss: 0.37754589319229126\n",
      "Epoch: 66, Loss: 0.41344866156578064\n",
      "Epoch: 67, Loss: 0.41442883014678955\n",
      "Epoch: 68, Loss: 0.3487953841686249\n",
      "Epoch: 69, Loss: 0.36588263511657715\n",
      "Epoch: 70, Loss: 0.37637680768966675\n",
      "Epoch: 71, Loss: 0.3497428297996521\n",
      "Epoch: 72, Loss: 0.3520899713039398\n",
      "Epoch: 73, Loss: 0.3655451238155365\n",
      "Epoch: 74, Loss: 0.3444958031177521\n",
      "Epoch: 75, Loss: 0.3467840850353241\n",
      "Epoch: 76, Loss: 0.3514126241207123\n",
      "Epoch: 77, Loss: 0.328606516122818\n",
      "Epoch: 78, Loss: 0.3459516167640686\n",
      "Epoch: 79, Loss: 0.330676794052124\n",
      "Epoch: 80, Loss: 0.324255108833313\n",
      "Epoch: 81, Loss: 0.3267746865749359\n",
      "Epoch: 82, Loss: 0.3264353275299072\n",
      "Epoch: 83, Loss: 0.3212842345237732\n",
      "Epoch: 84, Loss: 0.307862788438797\n",
      "Epoch: 85, Loss: 0.3116114139556885\n",
      "Epoch: 86, Loss: 0.3073556125164032\n",
      "Epoch: 87, Loss: 0.3093116581439972\n",
      "Epoch: 88, Loss: 0.3390716016292572\n",
      "Epoch: 89, Loss: 0.32747578620910645\n",
      "Epoch: 90, Loss: 0.31512579321861267\n",
      "Epoch: 91, Loss: 0.3281075358390808\n",
      "Epoch: 92, Loss: 0.332415372133255\n",
      "Epoch: 93, Loss: 0.29569247364997864\n",
      "Epoch: 94, Loss: 0.3463437855243683\n",
      "Epoch: 95, Loss: 0.3008173704147339\n",
      "Epoch: 96, Loss: 0.3245094120502472\n",
      "Epoch: 97, Loss: 0.2878437936306\n",
      "Epoch: 98, Loss: 0.3203979432582855\n",
      "Epoch: 99, Loss: 0.293067067861557\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model instantiation\n",
    "demo_model = MLP([thermochemical_data.shape[1], 400, 400, 400, 400, thermochemical_data.shape[1]-3]).to(device)\n",
    "\n",
    "# Data loading\n",
    "thermochem_states1 = labeled_data[:, 0:11]\n",
    "thermochem_states2 = labeled_data[:, 11:]\n",
    "thermochem_states1[:, 2:] = np.clip(thermochem_states1[:, 2:], 0, 1)\n",
    "thermochem_states2[:, 2:] = np.clip(thermochem_states2[:, 2:], 0, 1)\n",
    "\n",
    "features = torch.tensor(BCT(thermochem_states1), dtype=torch.float32).to(device)\n",
    "labels = torch.tensor(BCT(thermochem_states2[:, 2:-1]) - BCT(thermochem_states1[:, 2:-1]), dtype=torch.float32).to(device)\n",
    "\n",
    "features_mean = torch.mean(features, dim=0)\n",
    "features_std = torch.std(features, dim=0)\n",
    "features = (features - features_mean) / features_std\n",
    "\n",
    "labels_mean = torch.mean(labels, dim=0)\n",
    "labels_std = torch.std(labels, dim=0)\n",
    "labels = (labels - labels_mean) / labels_std\n",
    "\n",
    "# Training\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(demo_model.parameters(), lr=1e-3)\n",
    "\n",
    "demo_model.train()  \n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    preds = demo_model(features)\n",
    "    loss = criterion(preds, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"Epoch: {}, Loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "torch.save(\n",
    "    {\n",
    "        'net': demo_model.state_dict(),\n",
    "        'data_in_mean': features_mean.cpu().numpy(),\n",
    "        'data_in_std': features_std.cpu().numpy(),\n",
    "        'data_target_mean': labels_mean.cpu().numpy(),\n",
    "        'data_target_std': labels_std.cpu().numpy(),\n",
    "    },\n",
    "    \"demo_model.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880b7a2",
   "metadata": {},
   "source": [
    "#### Model testing\n",
    "\n",
    "Model testing is closely associated with a specific testing dataset, enabling the evaluation of the trained modelsâ€™ performance. DFODE-kit can directly operate on HDF5 files, adhering to a predefined format that facilitates seamless data integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e4c7c8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-06 3.00023000e+02 1.02883000e+05 1.93180336e-41\n",
      " 2.85116114e-02 1.79077845e-47 1.07332764e-47 8.89073823e-48\n",
      " 2.26269091e-01 6.21366281e-38 2.13981345e-52 7.45219298e-01]\n",
      "[1.00000000e-06 2.39472000e+03 1.02881031e+05 7.49624466e-05\n",
      " 1.22141488e-03 3.92780145e-04 5.72190086e-03 2.40164611e-01\n",
      " 7.20252466e-03 1.74150538e-06 1.89174168e-07 7.45219875e-01]\n",
      "[1.00000000e-06 3.00027000e+02 1.02907000e+05 1.93286729e-41\n",
      " 2.85116114e-02 1.78235919e-47 1.06644844e-47 8.84346360e-48\n",
      " 2.26269091e-01 6.19316244e-38 2.15120479e-52 7.45219298e-01]\n",
      "[1.00000000e-06 2.39477000e+03 1.02903030e+05 7.49969233e-05\n",
      " 1.22168596e-03 3.92980850e-04 5.72353273e-03 2.40161469e-01\n",
      " 7.20395248e-03 1.74209961e-06 1.89277964e-07 7.45219451e-01]\n",
      "[1.00000000e-06 3.00001000e+02 1.01330000e+05 1.91643344e-41\n",
      " 2.85116114e-02 9.46442269e-48 7.60276420e-48 2.76612710e-48\n",
      " 2.26269091e-01 3.32684024e-38 4.66902696e-53 7.45219298e-01]\n",
      "[1.00000000e-06 2.38895000e+03 1.01699005e+05 7.50156151e-05\n",
      " 1.22005459e-03 3.91848170e-04 5.69274477e-03 2.40192126e-01\n",
      " 7.20681180e-03 1.71047415e-06 1.89527781e-07 7.45219499e-01]\n",
      "[1.00000000e-06 3.00153000e+02 1.01724000e+05 1.97363223e-41\n",
      " 2.85116114e-02 1.28993222e-47 9.45017751e-48 4.82226417e-48\n",
      " 2.26269091e-01 4.57847543e-38 8.90408634e-53 7.45219298e-01]\n",
      "[1.00000000e-06 2.38955000e+03 1.01724008e+05 7.50057667e-05\n",
      " 1.22001008e-03 3.92002487e-04 5.69628568e-03 2.40190753e-01\n",
      " 7.20457271e-03 1.71293959e-06 1.89346225e-07 7.45219468e-01]\n",
      "[1.00000000e-06 3.00299000e+02 1.02251000e+05 2.08520439e-41\n",
      " 2.85116114e-02 1.57163214e-47 1.09133769e-47 6.51989801e-48\n",
      " 2.26269091e-01 5.49369933e-38 1.29516659e-52 7.45219298e-01]\n",
      "[1.00000000e-06 2.39053000e+03 1.01934013e+05 7.49657219e-05\n",
      " 1.22011971e-03 3.91934790e-04 5.69956648e-03 2.40188532e-01\n",
      " 7.20363326e-03 1.71819593e-06 1.89199772e-07 7.45219340e-01]\n",
      "[1.00000000e-06 3.00195000e+02 1.02422000e+05 2.00590718e-41\n",
      " 2.85116114e-02 1.67647684e-47 1.10282448e-47 7.58710909e-48\n",
      " 2.26269091e-01 5.85060494e-38 1.58257085e-52 7.45219298e-01]\n",
      "[1.00000000e-06 2.39111000e+03 1.02062015e+05 7.49554585e-05\n",
      " 1.22020331e-03 3.92008839e-04 5.70235256e-03 2.40185731e-01\n",
      " 7.20285806e-03 1.72126243e-06 1.89171845e-07 7.45219981e-01]\n",
      "[1.00000000e-06 3.00215000e+02 1.02704000e+05 2.06367415e-41\n",
      " 2.85116114e-02 1.76427787e-47 1.13317337e-47 8.21783160e-48\n",
      " 2.26269091e-01 6.12111354e-38 1.78460243e-52 7.45219298e-01]\n",
      "[1.00000000e-06 2.39203000e+03 1.02282019e+05 7.49273668e-05\n",
      " 1.22035663e-03 3.92008472e-04 5.70590549e-03 2.40183421e-01\n",
      " 7.20215740e-03 1.72635818e-06 1.89104499e-07 7.45219308e-01]\n",
      "[1.00000000e-06 3.00178000e+02 1.02882000e+05 2.02179728e-41\n",
      " 2.85116114e-02 1.81579516e-47 1.14102121e-47 8.65438838e-48\n",
      " 2.26269091e-01 6.27502239e-38 1.93196381e-52 7.45219298e-01]\n",
      "[1.00000000e-06 2.39307000e+03 1.02499024e+05 7.49019096e-05\n",
      " 1.22052507e-03 3.92066996e-04 5.71035174e-03 2.40179520e-01\n",
      " 7.20113559e-03 1.73193843e-06 1.88997916e-07 7.45219578e-01]\n",
      "[1.00000000e-06 3.00082000e+02 1.02870000e+05 1.96520039e-41\n",
      " 2.85116114e-02 1.82458785e-47 1.12138050e-47 8.90318160e-48\n",
      " 2.26269091e-01 6.30342803e-38 2.03595382e-52 7.45219298e-01]\n",
      "[1.00000000e-06 2.39361000e+03 1.02624026e+05 7.49081310e-05\n",
      " 1.22070080e-03 3.92233692e-04 5.71367022e-03 2.40176402e-01\n",
      " 7.20085032e-03 1.73491870e-06 1.89026864e-07 7.45219311e-01]\n",
      "[1.00000000e-06 3.00050000e+02 1.02867000e+05 1.93877055e-41\n",
      " 2.85116114e-02 1.80911289e-47 1.09278536e-47 8.97647790e-48\n",
      " 2.26269091e-01 6.26055096e-38 2.09630688e-52 7.45219298e-01]\n",
      "[1.00000000e-06 2.39419000e+03 1.02757029e+05 7.49129398e-05\n",
      " 1.22092296e-03 3.92377307e-04 5.71694631e-03 2.40172444e-01\n",
      " 7.20099216e-03 1.73821801e-06 1.89038002e-07 7.45219477e-01]\n",
      "[1.00000000e-06 3.00043000e+02 1.02892000e+05 1.94509956e-41\n",
      " 2.85116114e-02 1.80262080e-47 1.08536938e-47 8.93273385e-48\n",
      " 2.26269091e-01 6.24408027e-38 2.12199657e-52 7.45219298e-01]\n",
      "[1.00000000e-06 2.39459000e+03 1.02847030e+05 7.49301571e-05\n",
      " 1.22116415e-03 3.92560772e-04 5.71981751e-03 2.40168495e-01\n",
      " 7.20149697e-03 1.74057076e-06 1.89080543e-07 7.45219606e-01]\n",
      "Saved processed dataset: 0.0001 in cvode_integration group\n",
      "Saved processed dataset: 0.00011 in cvode_integration group\n",
      "Saved processed dataset: 1e-05 in cvode_integration group\n",
      "Saved processed dataset: 2e-05 in cvode_integration group\n",
      "Saved processed dataset: 3e-05 in cvode_integration group\n",
      "Saved processed dataset: 4e-05 in cvode_integration group\n",
      "Saved processed dataset: 5e-05 in cvode_integration group\n",
      "Saved processed dataset: 6e-05 in cvode_integration group\n",
      "Saved processed dataset: 7e-05 in cvode_integration group\n",
      "Saved processed dataset: 8e-05 in cvode_integration group\n",
      "Saved processed dataset: 9e-05 in cvode_integration group\n",
      "Inspecting HDF5 file: tutorial_data.h5\n",
      "\n",
      "Metadata in the HDF5 file:\n",
      "mechanism: /data1/kexiao/projects/dfode_project/DFODE-kit/mechanisms/Burke2012_s9r23.yaml\n",
      "root_directory: /data1/kexiao/projects/dfode_project/DFODE-kit/tutorials/oneD_freely_propagating_flame\n",
      "species_names: ['T' 'p' 'H' 'H2' 'O' 'OH' 'H2O' 'O2' 'HO2' 'H2O2' 'N2']\n",
      "\n",
      "Groups and datasets in the HDF5 file:\n",
      "Group: cvode_integration\n",
      "  Dataset: 0.0001, Shape: (500, 12)\n",
      "  Dataset: 0.00011, Shape: (500, 12)\n",
      "  Dataset: 1e-05, Shape: (500, 12)\n",
      "  Dataset: 2e-05, Shape: (500, 12)\n",
      "  Dataset: 3e-05, Shape: (500, 12)\n",
      "  Dataset: 4e-05, Shape: (500, 12)\n",
      "  Dataset: 5e-05, Shape: (500, 12)\n",
      "  Dataset: 6e-05, Shape: (500, 12)\n",
      "  Dataset: 7e-05, Shape: (500, 12)\n",
      "  Dataset: 8e-05, Shape: (500, 12)\n",
      "  Dataset: 9e-05, Shape: (500, 12)\n",
      "Group: mesh\n",
      "  Dataset: Cx, Shape: (500, 1)\n",
      "  Dataset: Cy, Shape: (500, 1)\n",
      "  Dataset: Cz, Shape: (500, 1)\n",
      "  Dataset: V, Shape: (500, 1)\n",
      "Group: scalar_fields\n",
      "  Dataset: 0.0001, Shape: (500, 11)\n",
      "  Dataset: 0.00011, Shape: (500, 11)\n",
      "  Dataset: 1e-05, Shape: (500, 11)\n",
      "  Dataset: 2e-05, Shape: (500, 11)\n",
      "  Dataset: 3e-05, Shape: (500, 11)\n",
      "  Dataset: 4e-05, Shape: (500, 11)\n",
      "  Dataset: 5e-05, Shape: (500, 11)\n",
      "  Dataset: 6e-05, Shape: (500, 11)\n",
      "  Dataset: 7e-05, Shape: (500, 11)\n",
      "  Dataset: 8e-05, Shape: (500, 11)\n",
      "  Dataset: 9e-05, Shape: (500, 11)\n"
     ]
    }
   ],
   "source": [
    "model_settings = {\n",
    "    'model_path': \"demo_model.pt\",\n",
    "    'device': 'cpu',\n",
    "    'model_class': MLP,\n",
    "    'model_layers': [thermochemical_data.shape[1], 400, 400, 400, 400, thermochemical_data.shape[1]-3],\n",
    "    'time_step': 1e-6,\n",
    "    'mech': f\"{DFODE_ROOT}/mechanisms/Burke2012_s9r23.yaml\"\n",
    "}\n",
    "integrate_h5(\"tutorial_data.h5\", 1e-6, nn_integration=False, model_settings=model_settings)\n",
    "\n",
    "touch_h5(\"tutorial_data.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xk-flamebench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
