{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44caac4b",
   "metadata": {},
   "source": [
    "This is a tutorial for the DFODE-kit package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b1a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dfode_kit.df_interface import (\n",
    "    OneDFreelyPropagatingFlameConfig,\n",
    "    setup_one_d_flame_case,\n",
    "    df_to_h5,\n",
    ")\n",
    "from dfode_kit.data_operations import touch_h5, get_TPY_from_h5, random_perturb\n",
    "\n",
    "DFODE_ROOT = os.environ['DFODE_ROOT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032661c",
   "metadata": {},
   "source": [
    "### A brief introduction to the DFODE method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a592b7b",
   "metadata": {},
   "source": [
    "#### Low-dimensional manifold sampling\n",
    "\n",
    "A key challenge in preparing training data is achieving sufficient coverage of the relevant thermochemical composition space, which is often prohibitively high-dimensional when detailed chemistry involves tens to hundreds of species. \n",
    "\n",
    "To address this, DFODE-kit adopts a low-dimensional\n",
    "manifold sampling strategy, where thermochemical states are extracted from canonical flame configurations that retain the essential topology of high-dimensional turbulent flames. This approach ensures both computational efficiency and physical representativeness of the training datasets.\n",
    "\n",
    "In this tutorial, we will demonstrate how to use DFODE-kit to sample a low-dimensional manifold of thermochemical states from a one-dimensional laminar freely propagating flame simulated with DeepFlame. The following code block could also be found in `case_init.ipynb` files within the case templates provides in the `cases` directory. It is used to initialize the simulation and update the dictionary files for the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58d8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving premixed flame...\n",
      "Laminar Flame Speed      :   2.3489328863 m/s\n",
      "Laminar Flame Thickness  :   0.0003694362 m\n",
      "One-dimensional flame case setup completed at: /data1/kexiao/projects/dfode_project/DFODE-kit/tutorials/oneD_freely_propagating_flame\n"
     ]
    }
   ],
   "source": [
    "# Operating condition settings\n",
    "config_dict = {\n",
    "    \"mechanism\": f\"{DFODE_ROOT}/mechanisms/Burke2012_s9r23.yaml\",\n",
    "    \"T0\": 300,\n",
    "    \"p0\": 101325,\n",
    "    \"fuel\": \"H2:1\",\n",
    "    \"oxidizer\": \"O2:0.21,N2:0.79\",\n",
    "    \"eq_ratio\": 1.0,\n",
    "}\n",
    "config = OneDFreelyPropagatingFlameConfig(**config_dict)\n",
    "\n",
    "# Simulation settings\n",
    "settings = {\n",
    "    \"sim_time_step\": 1e-6,\n",
    "    \"sim_write_interval\": 1e-5,\n",
    "    \"num_output_steps\": 100,\n",
    "}\n",
    "config.update_config(settings)\n",
    "\n",
    "# Setup the case and update dictionary files\n",
    "setup_one_d_flame_case(config, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbbe369",
   "metadata": {},
   "source": [
    "Note that at the point, the simulation is not yet started. The user would need to ensure a working version of DeepFlame is available and run the `Allrun` script from command line to start the simulation.\n",
    "\n",
    "```bash\n",
    "./Allrun\n",
    "```\n",
    "\n",
    "After the simulation is completed, we proceed to use DFODE-kit to gather and manage the thermochemical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd60205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species names: ['T', 'p', 'H', 'H2', 'O', 'OH', 'H2O', 'O2', 'HO2', 'H2O2', 'N2']\n",
      "Saved concatenated arrays to /data1/kexiao/projects/dfode_project/DFODE-kit/tutorials/oneD_freely_propagating_flame/tutorial_data.h5\n"
     ]
    }
   ],
   "source": [
    "df_to_h5(\n",
    "    root_dir=f\"{DFODE_ROOT}/tutorials/oneD_freely_propagating_flame\",\n",
    "    mechanism=f\"{DFODE_ROOT}/mechanisms/Burke2012_s9r23.yaml\",\n",
    "    hdf5_file_path=f\"{DFODE_ROOT}/tutorials/oneD_freely_propagating_flame/tutorial_data.h5\",\n",
    "    include_mesh=True,\n",
    ")\n",
    "\n",
    "# The above is equivalent to the following cli command:\n",
    "# dfode-kit sample --mech Burke2012_s9r23.yaml \\\n",
    "#     --case tutorials/oneD_freely_propagating_flame \\\n",
    "#     --save tutorials/oneD_freely_propagating_flame/tutorial_data.h5 \\\n",
    "#     --include-mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b991ab21",
   "metadata": {},
   "source": [
    "Checking the contents of the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b45c7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting HDF5 file: tutorial_data.h5\n",
      "\n",
      "Metadata in the HDF5 file:\n",
      "mechanism: /data1/kexiao/projects/dfode_project/DFODE-kit/mechanisms/Burke2012_s9r23.yaml\n",
      "root_directory: /data1/kexiao/projects/dfode_project/DFODE-kit/tutorials/oneD_freely_propagating_flame\n",
      "species_names: ['T' 'p' 'H' 'H2' 'O' 'OH' 'H2O' 'O2' 'HO2' 'H2O2' 'N2']\n",
      "\n",
      "Groups and datasets in the HDF5 file:\n",
      "Group: mesh\n",
      "  Dataset: Cx, Shape: (500, 1)\n",
      "  Dataset: Cy, Shape: (500, 1)\n",
      "  Dataset: Cz, Shape: (500, 1)\n",
      "  Dataset: V, Shape: (500, 1)\n",
      "Group: scalar_fields\n",
      "  Dataset: 0.0001, Shape: (500, 11)\n",
      "  Dataset: 0.00011, Shape: (500, 11)\n",
      "  Dataset: 0.00012, Shape: (500, 11)\n",
      "  Dataset: 0.00013, Shape: (500, 11)\n",
      "  Dataset: 0.00014, Shape: (500, 11)\n",
      "  Dataset: 0.00015, Shape: (500, 11)\n",
      "  Dataset: 0.00016, Shape: (500, 11)\n",
      "  Dataset: 0.00017, Shape: (500, 11)\n",
      "  Dataset: 0.00018, Shape: (500, 11)\n",
      "  Dataset: 0.00019, Shape: (500, 11)\n",
      "  Dataset: 0.0002, Shape: (500, 11)\n",
      "  Dataset: 0.00021, Shape: (500, 11)\n",
      "  Dataset: 0.00022, Shape: (500, 11)\n",
      "  Dataset: 0.00023, Shape: (500, 11)\n",
      "  Dataset: 0.00024, Shape: (500, 11)\n",
      "  Dataset: 0.00025, Shape: (500, 11)\n",
      "  Dataset: 0.00026, Shape: (500, 11)\n",
      "  Dataset: 0.00027, Shape: (500, 11)\n",
      "  Dataset: 0.00028, Shape: (500, 11)\n",
      "  Dataset: 0.00029, Shape: (500, 11)\n",
      "  Dataset: 0.0003, Shape: (500, 11)\n",
      "  Dataset: 0.00031, Shape: (500, 11)\n",
      "  Dataset: 0.00032, Shape: (500, 11)\n",
      "  Dataset: 0.00033, Shape: (500, 11)\n",
      "  Dataset: 0.00034, Shape: (500, 11)\n",
      "  Dataset: 0.00035, Shape: (500, 11)\n",
      "  Dataset: 0.00036, Shape: (500, 11)\n",
      "  Dataset: 0.00037, Shape: (500, 11)\n",
      "  Dataset: 0.00038, Shape: (500, 11)\n",
      "  Dataset: 0.00039, Shape: (500, 11)\n",
      "  Dataset: 0.0004, Shape: (500, 11)\n",
      "  Dataset: 0.00041, Shape: (500, 11)\n",
      "  Dataset: 0.00042, Shape: (500, 11)\n",
      "  Dataset: 0.00043, Shape: (500, 11)\n",
      "  Dataset: 0.00044, Shape: (500, 11)\n",
      "  Dataset: 0.00045, Shape: (500, 11)\n",
      "  Dataset: 0.00046, Shape: (500, 11)\n",
      "  Dataset: 0.00047, Shape: (500, 11)\n",
      "  Dataset: 0.00048, Shape: (500, 11)\n",
      "  Dataset: 0.00049, Shape: (500, 11)\n",
      "  Dataset: 0.0005, Shape: (500, 11)\n",
      "  Dataset: 0.00051, Shape: (500, 11)\n",
      "  Dataset: 0.00052, Shape: (500, 11)\n",
      "  Dataset: 0.00053, Shape: (500, 11)\n",
      "  Dataset: 0.00054, Shape: (500, 11)\n",
      "  Dataset: 0.00055, Shape: (500, 11)\n",
      "  Dataset: 0.00056, Shape: (500, 11)\n",
      "  Dataset: 0.00057, Shape: (500, 11)\n",
      "  Dataset: 0.00058, Shape: (500, 11)\n",
      "  Dataset: 0.00059, Shape: (500, 11)\n",
      "  Dataset: 0.0006, Shape: (500, 11)\n",
      "  Dataset: 0.00061, Shape: (500, 11)\n",
      "  Dataset: 0.00062, Shape: (500, 11)\n",
      "  Dataset: 0.00063, Shape: (500, 11)\n",
      "  Dataset: 0.00064, Shape: (500, 11)\n",
      "  Dataset: 0.00065, Shape: (500, 11)\n",
      "  Dataset: 0.00066, Shape: (500, 11)\n",
      "  Dataset: 0.00067, Shape: (500, 11)\n",
      "  Dataset: 0.00068, Shape: (500, 11)\n",
      "  Dataset: 0.00069, Shape: (500, 11)\n",
      "  Dataset: 0.0007, Shape: (500, 11)\n",
      "  Dataset: 0.00071, Shape: (500, 11)\n",
      "  Dataset: 0.00072, Shape: (500, 11)\n",
      "  Dataset: 0.00073, Shape: (500, 11)\n",
      "  Dataset: 0.00074, Shape: (500, 11)\n",
      "  Dataset: 0.00075, Shape: (500, 11)\n",
      "  Dataset: 0.00076, Shape: (500, 11)\n",
      "  Dataset: 0.00077, Shape: (500, 11)\n",
      "  Dataset: 0.00078, Shape: (500, 11)\n",
      "  Dataset: 0.00079, Shape: (500, 11)\n",
      "  Dataset: 0.0008, Shape: (500, 11)\n",
      "  Dataset: 0.00081, Shape: (500, 11)\n",
      "  Dataset: 0.00082, Shape: (500, 11)\n",
      "  Dataset: 0.00083, Shape: (500, 11)\n",
      "  Dataset: 0.00084, Shape: (500, 11)\n",
      "  Dataset: 0.00085, Shape: (500, 11)\n",
      "  Dataset: 0.00086, Shape: (500, 11)\n",
      "  Dataset: 0.00087, Shape: (500, 11)\n",
      "  Dataset: 0.00088, Shape: (500, 11)\n",
      "  Dataset: 0.00089, Shape: (500, 11)\n",
      "  Dataset: 0.0009, Shape: (500, 11)\n",
      "  Dataset: 0.00091, Shape: (500, 11)\n",
      "  Dataset: 0.00092, Shape: (500, 11)\n",
      "  Dataset: 0.00093, Shape: (500, 11)\n",
      "  Dataset: 0.00094, Shape: (500, 11)\n",
      "  Dataset: 0.00095, Shape: (500, 11)\n",
      "  Dataset: 0.00096, Shape: (500, 11)\n",
      "  Dataset: 0.00097, Shape: (500, 11)\n",
      "  Dataset: 0.00098, Shape: (500, 11)\n",
      "  Dataset: 0.00099, Shape: (500, 11)\n",
      "  Dataset: 0.001, Shape: (500, 11)\n",
      "  Dataset: 0.00101, Shape: (500, 11)\n",
      "  Dataset: 1e-05, Shape: (500, 11)\n",
      "  Dataset: 2e-05, Shape: (500, 11)\n",
      "  Dataset: 3e-05, Shape: (500, 11)\n",
      "  Dataset: 4e-05, Shape: (500, 11)\n",
      "  Dataset: 5e-05, Shape: (500, 11)\n",
      "  Dataset: 6e-05, Shape: (500, 11)\n",
      "  Dataset: 7e-05, Shape: (500, 11)\n",
      "  Dataset: 8e-05, Shape: (500, 11)\n",
      "  Dataset: 9e-05, Shape: (500, 11)\n"
     ]
    }
   ],
   "source": [
    "touch_h5(\"tutorial_data.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779899a3",
   "metadata": {},
   "source": [
    "#### Data augmentation and labeling\n",
    "\n",
    "While laminar canonical flames provide fundamental thermochemical states,their trajectory-aligned sampling in composition space poses significant limitations for a posteriori modeling applications. First, these sampled states are confined to predefined flamelet manifolds, making the trained model highly sensitive to perturbations and leading to an over-constrained representation. Second, the sampled states span a lower-dimensional subspace, which fails to encompass the full range of thermochemical variations encountered in turbulent combustion. As a result, the model becomes vulnerable to off-manifold perturbations—deviations from the training manifold that frequently arise in turbulent reacting flows.\n",
    "\n",
    "To tackle this challenge, a data augmentation strategy is employed, where collected states are perturbed to simulate the effects of multi-dimensional transport and turbulence disturbances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece01cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets in scalar_fields group: 101\n",
      "[3.00023e+02 1.02883e+05 1.50501e-41 2.85116e-02 1.63881e-47 9.68647e-48\n",
      " 8.28493e-48 2.26269e-01 5.70836e-38 2.00401e-52 7.45219e-01]\n",
      "[2.86602088e+02 1.02979382e+05 2.20858138e-42 2.06611700e-02\n",
      " 4.98106786e-49 4.41905979e-50 6.74487245e-52 2.34119830e-01\n",
      " 1.36522580e-41 2.53278147e-54 7.45219000e-01]\n"
     ]
    }
   ],
   "source": [
    "thermochemical_data = get_TPY_from_h5(\"tutorial_data.h5\")\n",
    "print(thermochemical_data[0])\n",
    "\n",
    "aug_thermochemical_data = random_perturb(thermochemical_data)\n",
    "print(aug_thermochemical_data[0])\n",
    "\n",
    "np.save(\"tutorial_data_aug.npy\", aug_thermochemical_data)\n",
    "\n",
    "# The above is equivalent to the following cli command:\n",
    "# dfode-kit augment --h5_file tutorial_data.h5 \\\n",
    "#     --output_file tutorial_data_aug.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f2d8f",
   "metadata": {},
   "source": [
    "The CVODE integrator from Cantera is used for time integration and to provide supervised learning labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff47da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets in scalar_fields group: 101\n",
      "[3.00023e+02 1.02883e+05 1.50501e-41 2.85116e-02 1.63881e-47 9.68647e-48\n",
      " 8.28493e-48 2.26269e-01 5.70836e-38 2.00401e-52 7.45219e-01]\n",
      "[3.58226294e+02 1.02713988e+05 1.83370682e-44 3.78931118e-02\n",
      " 2.36019454e-43 2.76274685e-50 7.70768939e-51 2.16887888e-01\n",
      " 8.11918735e-35 8.00910288e-50 7.45219000e-01]\n"
     ]
    }
   ],
   "source": [
    "thermochemical_data = get_TPY_from_h5(\"tutorial_data.h5\")\n",
    "print(thermochemical_data[0])\n",
    "\n",
    "aug_thermochemical_data = random_perturb(thermochemical_data)\n",
    "print(aug_thermochemical_data[0])\n",
    "\n",
    "np.save(\"tutorial_data_aug.npy\", aug_thermochemical_data)\n",
    "\n",
    "# The above is equivalent to the following cli command:\n",
    "# dfode-kit label --mech MECH \\\n",
    "#     --time TIME\n",
    "#     --source SOURCE \n",
    "#     --save SAVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc291e95",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5aa0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2880b7a2",
   "metadata": {},
   "source": [
    "#### Model testing\n",
    "\n",
    "Model testing is closely associated with a specific testing dataset, enabling the evaluation of the trained models’ performance. DFODE-kit can directly operate on HDF5 files, adhering to a predefined format that facilitates seamless data integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7c8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xk-flamebench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
